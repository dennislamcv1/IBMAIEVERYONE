<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <link rel="stylesheet" href="https://unpkg.com/@highlightjs/cdn-assets@10.7.1/styles/default.min.css">
  </head>
  <body>
    <img src="https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-AI0103EN-SkillsNetwork/Readings/Module4/images/idsn_logo.PNG" width="300">
    <h1>Watson in use at Coca-Cola Company</h1>
    <p>This case study represents just one of the successful implementations of Watson Services for Core ML across the world. You may recognize this company and the features in use from other modules in this course and the Introduction to AI course. Read the case study summarized below.</p>
    <p>Apple and IBM began collaborating in 2014 to make Watson AI services and the Apple ML framework, Core ML, available through apps on mobile iOS devices, even when they are not connected to a network.</p>
    <h1>COCA-COLA COMPANY</h1>
    <p>The Coca-Cola Company is interested in the possible in-field applications of Watson Services for Core ML, and is exploring visual recognition for problem identification, cognitive diagnosis and augmented repair of their beverage dispensing machines.</p>
    <p>Previously, field technicians relied on their own expertise and experience to resolve issues with a wide range of beverage dispensing machines. On location, connectivity to the internet could not be assumed – the client site may be rural, or the machine located in the depths of a building where there is no data reception. This made accessing information for support and troubleshooting very difficult.</p>
    <p>With Watson Services for Core ML, Coca-Cola developed an app that uses visual recognition and augmented reality to help the technician on-site. Using the app, the technician can use their iPhone or iPad camera to diagnose system problems via a virtual overlay and guided instructions pulled from the cloud. Watson Visual Recognition on the device helps the technician identify unfamiliar systems and parts.</p>
    <p>Data is captured as the technician is working on resolving the issue, and that data is added to the cloud once the device has internet connectivity, meaning information can be shared between field technicians faster than ever before. Field technicians can now diagnose and correct an enormous array of problems on-site, with little or no network connectivity.</p>
    <p>To read the full case study, go to<a href="https://www.ibm.com/watson/stories/coreml?utm_medium=Exinfluencer&#x26;utm_source=Exinfluencer&#x26;utm_content=000026UJ&#x26;utm_term=10006555&#x26;utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkAI0103ENSkillsNetwork20648538-2022-01-01" target="_blank" rel="external">With Watson, technicians are empowered to make the right repairs. The first time. Anywhere.</a></p>
    <h2></h2>
    <h3 align="center">© IBM Corporation 2020. All rights reserved.</h3>
    <h3></h3>
    <script>window.addEventListener('load', function() {
snFaculty.inject();
});</script>
    <script src="https://skills-network-assets.s3.us.cloud-object-storage.appdomain.cloud/scripts/inject.43989f87.js"></script>
    <script src="https://unpkg.com/@highlightjs/cdn-assets@10.7.1/highlight.min.js"></script>
    <script src="https://unpkg.com/highlightjs-badge@0.1.9/highlightjs-badge.min.js"></script>
  </body>
</html>
